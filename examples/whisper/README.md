# Real-time example with whisper.cpp

Pipe in audio from file or microphone:

```
ffmpeg -hide_banner -loglevel error -f avfoundation -i ":1" -f f32le -ar 16000 -acodec pcm_f32le -ac 1 pipe:1  | ./target/debug/mel_spec_example
```

As a temporary measure please use the [whisper-rs
fork](https://github.com/wavey-ai/whisper-rs)

```
whisper-rs = { path = "../../whisper-rs", features = ["coreml"]}
```

## usage

*IMPORTANT* TARGA mel spectrogram images used for inference will saved in
`mel_out` for debugging purposes (you can re-run inference on each one,
frame indexes are printed first in the stdout output. However, this folder
will grow quickly if left running.

Transcribed speech will be printed to stdout:

```
mel_spec/examples/whisper on ÓÇ† pipeline [‚úò!+?] is üì¶ v0.1.0 via ü¶Ä v1.72.0-nightly on ‚òÅÔ∏è  (us-east-1) took 7s
‚ùØ ffmpeg -hide_banner -loglevel error -f avfoundation -i ":1" -f f32le -ar 16000 -acodec pcm_f32le -ac 1 pipe:1  | ./target/debug/mel_spec_example
whisper_init_from_file_no_state: loading model from './../../../whisper.cpp/models/ggml-medium.en.bin'
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51864
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 1024
whisper_model_load: n_audio_head  = 16
whisper_model_load: n_audio_layer = 24
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 1024
whisper_model_load: n_text_head   = 16
whisper_model_load: n_text_layer  = 24
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 4
whisper_model_load: mem required  = 1899.00 MB (+   43.00 MB per decoder)
whisper_model_load: adding 1607 extra tokens
whisper_model_load: model ctx     = 1462.58 MB
whisper_model_load: model size    = 1462.12 MB
whisper_init_state: kv self size  =   42.00 MB
whisper_init_state: kv cross size =  140.62 MB
whisper_init_state: loading Core ML model from './../../../whisper.cpp/models/ggml-medium.en-encoder.mlmodelc'
whisper_init_state: first run on a device may take a while ...
whisper_init_state: Core ML model loaded
1136 [00:00:11.360]  once upon a time.
```
